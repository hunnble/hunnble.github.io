<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Noski"><title>第一个python爬虫:爬下豆瓣主页图片 · 北方公园</title><meta name="description" content="学而时戏之~~~早就听说python很好玩,也早就听说python很好玩,所以就用好玩的语言写好玩的东西。使用的版本3.5。所以很多很好的2.7版本教程不适用了。代码不长,分为几个功能:
首先当然是写照顾linux,定义编码格式和导入依赖模块12345678#!/usr/bin/env/python"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">北方公园</a></h3><div class="description"><p>痛苦如此持久，像蜗牛充满耐心地移动；快乐如此短暂，像兔子的尾巴掠过秋天的草原</p></div></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"></a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>第一个python爬虫:爬下豆瓣主页图片</a></h3></div><div class="post-content"><p>学而时戏之~~~<br>早就听说python很好玩,也早就听说python很好玩,所以就用好玩的语言写好玩的东西。<br>使用的版本3.5。所以很多很好的2.7版本教程不适用了。<br><a id="more"></a><br>代码不长,分为几个功能:</p>
<h3 id="首先当然是写照顾linux-定义编码格式和导入依赖模块"><a href="#首先当然是写照顾linux-定义编码格式和导入依赖模块" class="headerlink" title="首先当然是写照顾linux,定义编码格式和导入依赖模块"></a>首先当然是写照顾linux,定义编码格式和导入依赖模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env/python</span></div><div class="line"><span class="comment">#-*-encoding: utf-8-*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> urllib.request</div><div class="line"><span class="keyword">import</span> socket</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> os</div></pre></td></tr></table></figure>
<h3 id="把源码写入文件-这个就是爬下来页面看一看-豆瓣主页有两千一百多行"><a href="#把源码写入文件-这个就是爬下来页面看一看-豆瓣主页有两千一百多行" class="headerlink" title="把源码写入文件,这个就是爬下来页面看一看,豆瓣主页有两千一百多行~"></a>把源码写入文件,这个就是爬下来页面看一看,豆瓣主页有两千一百多行~</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveFile</span><span class="params">(data)</span>:</span></div><div class="line">    save_path = <span class="string">'D:/temp.out'</span></div><div class="line">    f_obj = open(save_path, <span class="string">'wb'</span>)</div><div class="line">    f_obj.write(data)</div><div class="line">    f_obj.close()</div></pre></td></tr></table></figure>
<h3 id="为图片指定输出目录"><a href="#为图片指定输出目录" class="headerlink" title="为图片指定输出目录"></a>为图片指定输出目录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">targetDir = <span class="string">r'D:/spiderImg'</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">destFile</span><span class="params">(path)</span>:</span></div><div class="line"><span class="comment"># 如果文件夹不存在就创建一个</span></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(targetDir):</div><div class="line">    os.mkdir(targetDir)</div><div class="line">pos = path.rindex(<span class="string">'/'</span>)</div><div class="line">t = os.path.join(targetDir, path[pos+<span class="number">1</span>:])</div><div class="line"><span class="keyword">return</span> t</div></pre></td></tr></table></figure>
<h3 id="核心模块-用简单的正则找到页面中的所有图片并爬取"><a href="#核心模块-用简单的正则找到页面中的所有图片并爬取" class="headerlink" title="核心模块,用简单的正则找到页面中的所有图片并爬取"></a>核心模块,用简单的正则找到页面中的所有图片并爬取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">print(<span class="string">'开始'</span>)</div><div class="line">url = <span class="string">'http://www.douban.com/'</span></div><div class="line">webHeader = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0'</span>&#125;</div><div class="line">req = urllib.request.Request(url=url, headers=webHeader)</div><div class="line">webPage = urllib.request.urlopen(req)</div><div class="line">contentBytes = webPage.read()</div><div class="line">saveFile(contentBytes)</div><div class="line"><span class="keyword">for</span> link, t <span class="keyword">in</span> set(re.findall(<span class="string">r'(http[s]?:[^\s]*?(jpg|png|gif))'</span>, str(contentBytes))):</div><div class="line">    print(link)</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        urllib.request.urlretrieve(link, destFile(link))</div><div class="line">        print(<span class="string">'\t\t成功'</span>)</div><div class="line">    <span class="keyword">except</span>:</div><div class="line">        print(<span class="string">'\t\t失败'</span>)</div><div class="line">print(<span class="string">'结束'</span>)</div></pre></td></tr></table></figure>
<p>这里我的正则很简单,[^\s]也就是非空格字符应该直接用\S,我一开始写的是http…什么都爬不下来。后来看了页面代码发现豆瓣主页图片是使用https的。于是改正,顺利完成！<br>这是在没有遇到阻拦的情况下爬一点数据,爬虫虽然是个小课题,但是深入发掘还是会有爬虫和反爬虫的矛盾对抗,各种框架的奇妙思路。千里之行,始于足下。晚安！</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2016-04-16</span><i class="fa fa-tag"></i><a href="/tag/python/" title="python" class="tag">python </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://hunnble.github.io/2016/04/16/第一个python爬虫-爬下豆瓣主页图片/,北方公园,第一个python爬虫:爬下豆瓣主页图片,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2016/04/17/第二个爬虫-requests和BeautifulSoup/" title="第二个爬虫:requests和BeautifulSoup" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2016/04/10/python回顾/" title="python回顾" class="btn">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>